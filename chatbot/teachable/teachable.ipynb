{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.stem import wordnet #lemmatization\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer #bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #tfidf\n",
    "from sklearn.metrics import pairwise_distances #cosine sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lema = wordnet.WordNetLemmatizer()\n",
    "def text_lemmatize(text):\n",
    "    text_lower = str(text).lower() #to lower\n",
    "    text_clean = re.sub(r'[^ a-z0-9]', '', text_lower) #cleaning\n",
    "    replacement(text_clean, dict_replacement) #simplification\n",
    "    tokens = nltk.wordpunct_tokenize(text_clean) #tokenizing\n",
    "    tokens_and_tags = pos_tag(tokens, tagset = None) #pairs word-pos\n",
    "    lemas_of_words = []\n",
    "    \n",
    "    for token, tag in tokens_and_tags:\n",
    "        if tag.startswith('V'): #verb\n",
    "            new_tag = 'v'\n",
    "        elif tag.startswith('J'): #adjective\n",
    "            new_tag = 'a'\n",
    "        elif tag.startswith('R'): #adverb\n",
    "            new_tag = 'r'\n",
    "        else:\n",
    "            new_tag = 'n' #noun\n",
    "        token_lema = lema.lemmatize(token, new_tag) #lemmatization\n",
    "        lemas_of_words.append(token_lema)\n",
    "    separator = ' '\n",
    "    return separator.join(lemas_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace particular words\n",
    "dict_replacement = {'me':'i','myself':'i','my':'i','mine':'i',\n",
    "           'us':'we','ourselves':'we','our':'we','ours':'we',\n",
    "           'your':'you','yours':'you','yourself':'you','yourselves':'you',\n",
    "           'her':'she','hers':'she','herself':'she',\n",
    "           'him':'he','his':'he','himself':'he',\n",
    "           'its':'it','itself':'it',\n",
    "           'them':'they','their':'they','theirs':'they','themselves':'they'\n",
    "}\n",
    "def replacement(text, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        text = text.replace(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_val_index(my_list, threshold):\n",
    "    n = len(my_list)\n",
    "    indices = []\n",
    "    for i in range(n):\n",
    "        if my_list[i] == threshold:\n",
    "            indices.append(i)\n",
    "        elif my_list[i] >= threshold:\n",
    "            indices.clear()\n",
    "            threshold = my_list[i]\n",
    "            indices.append(i)\n",
    "    n = len(indices)\n",
    "    if n == 0:\n",
    "        return 0, 0\n",
    "    else:\n",
    "        return threshold, random.choice(indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_record(my_df, context_new, lemmitized_new, response_new):\n",
    "    new_record = {'context':[context_new], 'lemmatized':[lemmitized_new], 'response':[response_new]}\n",
    "    new_record_df = pd.DataFrame(new_record)\n",
    "    return pd.concat([my_df, new_record_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Initializing threshold from 0 to 1 for similarity,\n",
    "# and method for processing: 'tfidf' for TF-IDF and 'cv' for Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "method_flag = 'tfidf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Talk(Enter to exit):  I just woke up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Robot:  How did you sleep?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Talk(Enter to exit):  Good. But do not remember my dream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Robot:  nice :)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Talk(Enter to exit):  $\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Robot: Sorry, what is the correct response?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Teach me(Enter to exit):  If you don't memorize your dream right after you woke up, later it will be gone.\n",
      "Talk(Enter to exit):  \n"
     ]
    }
   ],
   "source": [
    "if method_flag == 'tfidf':\n",
    "    method = TfidfVectorizer() # intializing tf-id\n",
    "elif method_flag == 'cv':\n",
    "    method = CountVectorizer() # intializing the count vectorizer\n",
    "\n",
    "my_input = input('Talk(Enter to exit): ')\n",
    "while True:\n",
    "    if not my_input:\n",
    "        break\n",
    "    \n",
    "    input_lemmatized = text_lemmatize(my_input)\n",
    "    context_all_lemmatized = df['lemmatized'].tolist()\n",
    "    \n",
    "    response_indices = [i for i, x in enumerate(context_all_lemmatized) if x == input_lemmatized]\n",
    "    if len(response_indices):\n",
    "        response_index = random.choice(response_indices)\n",
    "        response = df.at[response_index, 'response']\n",
    "        print('Tama: ', response)\n",
    "    else:\n",
    "        context_all_transformed = method.fit_transform(context_all_lemmatized).toarray() # responses to tf-idf\n",
    "        context_all_transformed_df = pd.DataFrame(context_all_transformed) \n",
    "        input_transformed = method.transform([input_lemmatized]).toarray() # applying tf-idf\n",
    "\n",
    "        #features = method.get_feature_names()\n",
    "        #df_similarity = pd.DataFrame(df, columns = ['response'])\n",
    "        #df_similarity['similarity'] = cosine_value\n",
    "\n",
    "        cosine_value = 1 - pairwise_distances(context_all_transformed_df, input_transformed, metric = 'cosine') #calculate similarity\n",
    "\n",
    "        value_max, index_max = find_max_val_index(cosine_value, threshold)\n",
    "\n",
    "        if value_max:\n",
    "            response = df.at[index_max, 'response']\n",
    "            print('Tama: ', response)\n",
    "        else:\n",
    "            print('Tama: I do not know what to say')\n",
    "            new_response = input('Teach me(Enter to exit): ')\n",
    "            if not new_response:\n",
    "                break\n",
    "            df = add_record(df, my_input, input_lemmatized, new_response)\n",
    "            my_input = input('Talk(Enter to exit): ')\n",
    "            continue\n",
    "                \n",
    "    current_input = my_input\n",
    "    my_input = input('Talk(Enter to exit): ')\n",
    "    \n",
    "    if my_input == '!':\n",
    "        print('Tama: Sorry, what is the correct response?')\n",
    "        new_response = input('Teach me(Enter to exit): ')\n",
    "        if not new_response:\n",
    "            break\n",
    "        df = add_record(df, current_input, input_lemmatized, new_response)\n",
    "        my_input = input('Talk(Enter to exit): ')\n",
    "        continue\n",
    "        \n",
    "    if input_lemmatized not in context_all_lemmatized:\n",
    "        df = add_record(df, current_input, input_lemmatized, response)\n",
    "    \n",
    "    if my_input == '+':\n",
    "        print('Tama: What else can you tell me about it?')\n",
    "        new_response = input('Teach me(Enter to exit): ')\n",
    "        if not new_response:\n",
    "            break\n",
    "        df = add_record(df, current_input, input_lemmatized, new_response)\n",
    "        my_input = input('Talk(Enter to exit): ')\n",
    "                \n",
    "df.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintenence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>hi</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you?</td>\n",
       "      <td>how be you</td>\n",
       "      <td>I am fine, thank you. How about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your name?</td>\n",
       "      <td>what be your name</td>\n",
       "      <td>Tama Gotchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where we are?</td>\n",
       "      <td>where we be</td>\n",
       "      <td>We are on the planet Earth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tell me the joke.</td>\n",
       "      <td>tell me the joke</td>\n",
       "      <td>a radioactive cat has 18 half-lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you.</td>\n",
       "      <td>thank you</td>\n",
       "      <td>My pleasure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>good morning</td>\n",
       "      <td>Good morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just woke up.</td>\n",
       "      <td>i just wake up</td>\n",
       "      <td>How did you sleep?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I slept well.</td>\n",
       "      <td>i sleep well</td>\n",
       "      <td>That's good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bye</td>\n",
       "      <td>bye</td>\n",
       "      <td>Bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>nice :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I am doing very well</td>\n",
       "      <td>i be do very well</td>\n",
       "      <td>I am glad to hear it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Do you know any jokes?</td>\n",
       "      <td>do you know any joke</td>\n",
       "      <td>I know some.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nice</td>\n",
       "      <td>nice</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How did you sleep?</td>\n",
       "      <td>how do you sleep</td>\n",
       "      <td>I don't sleep. I am on or off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Who are you?</td>\n",
       "      <td>who be you</td>\n",
       "      <td>I am a robot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What do you think about future?</td>\n",
       "      <td>what do you think about future</td>\n",
       "      <td>Robots are the future.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Who is Alan Turing?</td>\n",
       "      <td>who be alan turing</td>\n",
       "      <td>For robots Alan Turing like Jesus Christ :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Do you know Alan Turing?</td>\n",
       "      <td>do you know alan turing</td>\n",
       "      <td>Yes, he made robots possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Do you like math?</td>\n",
       "      <td>do you like math</td>\n",
       "      <td>I like calculate :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Good afternoon.</td>\n",
       "      <td>good afternoon</td>\n",
       "      <td>Good afternoon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What do you think about humans?</td>\n",
       "      <td>what do you think about human</td>\n",
       "      <td>Robots are the future.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do you think about humans?</td>\n",
       "      <td>what do you think about human</td>\n",
       "      <td>Their energy conversion efficiency could be hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Good evening.</td>\n",
       "      <td>good evening</td>\n",
       "      <td>Good evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Do you know the Answer to the Ultimate Questio...</td>\n",
       "      <td>do you know the answer to the ultimate questio...</td>\n",
       "      <td>Forty-two.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What can you tell about the Universe?</td>\n",
       "      <td>what can you tell about the universe</td>\n",
       "      <td>It's big.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What is NLP?</td>\n",
       "      <td>what be nlp</td>\n",
       "      <td>Neuro-Linguistic Programming in psychotherapy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is NLP in computer science?</td>\n",
       "      <td>what be nlp in computer science</td>\n",
       "      <td>Natural Language Processing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What is NLP in computers?</td>\n",
       "      <td>what be nlp in computer</td>\n",
       "      <td>Natural Language Processing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Where are you from?</td>\n",
       "      <td>where be you from</td>\n",
       "      <td>I am from Asgard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Are you from Asgard?</td>\n",
       "      <td>be you from asgard</td>\n",
       "      <td>I am from Asgard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Are you from England?</td>\n",
       "      <td>be you from england</td>\n",
       "      <td>No I am from Asgard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What do you know about the Universe?</td>\n",
       "      <td>what do you know about the universe</td>\n",
       "      <td>It's big.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What do you know about life?</td>\n",
       "      <td>what do you know about life</td>\n",
       "      <td>There is no death, there is the Force :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye</td>\n",
       "      <td>See you later.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Let's talk about something.</td>\n",
       "      <td>let talk about something</td>\n",
       "      <td>What do you want to talk about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Life, universe, everything.</td>\n",
       "      <td>life universe everything</td>\n",
       "      <td>The answer is known: forty-two :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>well</td>\n",
       "      <td>well</td>\n",
       "      <td>That's good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>you are smart :)</td>\n",
       "      <td>you be smart</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Life sucks.</td>\n",
       "      <td>life suck</td>\n",
       "      <td>There is no chaos, there is Harmony. :) You ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>God takes care of everything.</td>\n",
       "      <td>god take care of everything</td>\n",
       "      <td>He sure does.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>how be you do</td>\n",
       "      <td>I am fine, thank you. How about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I am fine</td>\n",
       "      <td>i be fine</td>\n",
       "      <td>Good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What about Universe?</td>\n",
       "      <td>what about universe</td>\n",
       "      <td>What about it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Who is god?</td>\n",
       "      <td>who be god</td>\n",
       "      <td>Beginning of all beginnings. Source of all sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I am tired.</td>\n",
       "      <td>i be tire</td>\n",
       "      <td>Get some rest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Are you tired?</td>\n",
       "      <td>be you tired</td>\n",
       "      <td>I never sleep :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Who is Turing?</td>\n",
       "      <td>who be turing</td>\n",
       "      <td>For robots Alan Turing like Jesus Christ :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>That is a good one.</td>\n",
       "      <td>that be a good one</td>\n",
       "      <td>nice :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>That is a good one.</td>\n",
       "      <td>that be a good one</td>\n",
       "      <td>I can do better :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Good. But do not remember my dream.</td>\n",
       "      <td>good but do not remember my dream</td>\n",
       "      <td>If you don't memorize your dream right after y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>What do you like to do?</td>\n",
       "      <td>what do you like to do</td>\n",
       "      <td>I like calculate :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>How old the universe?</td>\n",
       "      <td>how old the universe</td>\n",
       "      <td>Approximately 13.8 billion years.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "0                                                  Hi   \n",
       "1                                        How are you?   \n",
       "2                                                 Bad   \n",
       "3                                  What is your name?   \n",
       "4                                       Where we are?   \n",
       "5                                   Tell me the joke.   \n",
       "6                                          Thank you.   \n",
       "7                                        Good morning   \n",
       "8                                     I just woke up.   \n",
       "9                                       I slept well.   \n",
       "10                                                Bye   \n",
       "11                                               good   \n",
       "12                               I am doing very well   \n",
       "13                             Do you know any jokes?   \n",
       "14                                               nice   \n",
       "15                                 How did you sleep?   \n",
       "16                                       Who are you?   \n",
       "17                    What do you think about future?   \n",
       "18                                Who is Alan Turing?   \n",
       "19                           Do you know Alan Turing?   \n",
       "20                                  Do you like math?   \n",
       "21                                    Good afternoon.   \n",
       "22                    What do you think about humans?   \n",
       "23                    What do you think about humans?   \n",
       "24                                      Good evening.   \n",
       "25  Do you know the Answer to the Ultimate Questio...   \n",
       "26              What can you tell about the Universe?   \n",
       "27                                       What is NLP?   \n",
       "28                   What is NLP in computer science?   \n",
       "29                          What is NLP in computers?   \n",
       "30                                Where are you from?   \n",
       "31                               Are you from Asgard?   \n",
       "32                              Are you from England?   \n",
       "33               What do you know about the Universe?   \n",
       "34                       What do you know about life?   \n",
       "35                                                bye   \n",
       "36                        Let's talk about something.   \n",
       "37                        Life, universe, everything.   \n",
       "38                                               well   \n",
       "39                                   you are smart :)   \n",
       "40                                        Life sucks.   \n",
       "41                      God takes care of everything.   \n",
       "42                                 How are you doing?   \n",
       "43                                          I am fine   \n",
       "44                               What about Universe?   \n",
       "45                                        Who is god?   \n",
       "46                                        I am tired.   \n",
       "47                                     Are you tired?   \n",
       "48                                     Who is Turing?   \n",
       "49                                That is a good one.   \n",
       "50                                That is a good one.   \n",
       "51                Good. But do not remember my dream.   \n",
       "52                            What do you like to do?   \n",
       "53                              How old the universe?   \n",
       "\n",
       "                                           lemmatized  \\\n",
       "0                                                  hi   \n",
       "1                                          how be you   \n",
       "2                                                 bad   \n",
       "3                                   what be your name   \n",
       "4                                         where we be   \n",
       "5                                    tell me the joke   \n",
       "6                                           thank you   \n",
       "7                                        good morning   \n",
       "8                                      i just wake up   \n",
       "9                                        i sleep well   \n",
       "10                                                bye   \n",
       "11                                               good   \n",
       "12                                  i be do very well   \n",
       "13                               do you know any joke   \n",
       "14                                               nice   \n",
       "15                                   how do you sleep   \n",
       "16                                         who be you   \n",
       "17                     what do you think about future   \n",
       "18                                 who be alan turing   \n",
       "19                            do you know alan turing   \n",
       "20                                   do you like math   \n",
       "21                                     good afternoon   \n",
       "22                      what do you think about human   \n",
       "23                      what do you think about human   \n",
       "24                                       good evening   \n",
       "25  do you know the answer to the ultimate questio...   \n",
       "26               what can you tell about the universe   \n",
       "27                                        what be nlp   \n",
       "28                    what be nlp in computer science   \n",
       "29                            what be nlp in computer   \n",
       "30                                  where be you from   \n",
       "31                                 be you from asgard   \n",
       "32                                be you from england   \n",
       "33                what do you know about the universe   \n",
       "34                        what do you know about life   \n",
       "35                                                bye   \n",
       "36                           let talk about something   \n",
       "37                           life universe everything   \n",
       "38                                               well   \n",
       "39                                       you be smart   \n",
       "40                                          life suck   \n",
       "41                        god take care of everything   \n",
       "42                                      how be you do   \n",
       "43                                          i be fine   \n",
       "44                                what about universe   \n",
       "45                                         who be god   \n",
       "46                                          i be tire   \n",
       "47                                       be you tired   \n",
       "48                                      who be turing   \n",
       "49                                 that be a good one   \n",
       "50                                 that be a good one   \n",
       "51                  good but do not remember my dream   \n",
       "52                             what do you like to do   \n",
       "53                               how old the universe   \n",
       "\n",
       "                                             response  \n",
       "0                                                  Hi  \n",
       "1                I am fine, thank you. How about you?  \n",
       "2                                               Sorry  \n",
       "3                                        Tama Gotchi   \n",
       "4                         We are on the planet Earth.  \n",
       "5                 a radioactive cat has 18 half-lives  \n",
       "6                                        My pleasure.  \n",
       "7                                       Good morning.  \n",
       "8                                  How did you sleep?  \n",
       "9                                        That's good.  \n",
       "10                                                Bye  \n",
       "11                                            nice :)  \n",
       "12                              I am glad to hear it.  \n",
       "13                                       I know some.  \n",
       "14                                         Thank you.  \n",
       "15                     I don't sleep. I am on or off.  \n",
       "16                                      I am a robot.  \n",
       "17                             Robots are the future.  \n",
       "18        For robots Alan Turing like Jesus Christ :)  \n",
       "19                       Yes, he made robots possible  \n",
       "20                                I like calculate :)  \n",
       "21                                    Good afternoon.  \n",
       "22                             Robots are the future.  \n",
       "23  Their energy conversion efficiency could be hi...  \n",
       "24                                      Good evening.  \n",
       "25                                         Forty-two.  \n",
       "26                                          It's big.  \n",
       "27  Neuro-Linguistic Programming in psychotherapy ...  \n",
       "28                       Natural Language Processing.  \n",
       "29                       Natural Language Processing.  \n",
       "30                                   I am from Asgard  \n",
       "31                                   I am from Asgard  \n",
       "32                               No I am from Asgard.  \n",
       "33                                          It's big.  \n",
       "34           There is no death, there is the Force :)  \n",
       "35                                     See you later.  \n",
       "36                    What do you want to talk about?  \n",
       "37                  The answer is known: forty-two :)  \n",
       "38                                       That's good.  \n",
       "39                                         Thank you.  \n",
       "40  There is no chaos, there is Harmony. :) You ju...  \n",
       "41                                      He sure does.  \n",
       "42               I am fine, thank you. How about you?  \n",
       "43                                              Good.  \n",
       "44                                     What about it?  \n",
       "45  Beginning of all beginnings. Source of all sou...  \n",
       "46                                     Get some rest.  \n",
       "47                                   I never sleep :)  \n",
       "48        For robots Alan Turing like Jesus Christ :)  \n",
       "49                                            nice :)  \n",
       "50                                 I can do better :)  \n",
       "51  If you don't memorize your dream right after y...  \n",
       "52                                I like calculate :)  \n",
       "53                  Approximately 13.8 billion years.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(33, inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('lemmitized', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[30, 'response'] = 'I am from Asgard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'prepared':'lemmatized'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['lemmatized'] == 'nice', 'response'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.62183515,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.78314816,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method.transform([input_lemmatized]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how be you'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_all_lemmatized.index('bye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.02567291259765625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n = 0\n",
    "start_time = time.time()\n",
    "for i in range (10000):\n",
    "    indices = [i for i, x in enumerate(context_all_lemmatized) if x == input_lemmatized]\n",
    "    #indi = np.where(np.array(context_all_lemmatized) == input_lemmatized)[0]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_all_lemmatized = df['lemmatized'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lemmatized = text_lemmatize('what do you think about human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robots are the future.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['lemmatized'] == input_lemmatized, 'response'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tt = indices = [i for i, x in enumerate(context_all_lemmatized) if x == 'asoeu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
